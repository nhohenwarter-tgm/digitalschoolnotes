%\section*{Optical Character Recognition}
\cfoot{Adin Karic}
Optical Character Recognition oder auch Optische Zeichenerkennung bezeichnet die automatisierte Texterkennung innerhalb von Bildern. Mit diesem Verfahren können also Bilder eingelesen werden und die darin enthaltenen Zeichen als diese erkannt und ausgegeben werden. OCR ermöglicht es den Nutzern von Digital School Notes Bilder auf den Server zu laden, den textuellen Inhalt aus diesen Bildern zu filtern und als bearbeitbares Textelement in ein Heft einzufügen.

\insertpicture{images/ocr/ocrbsp.png}{Beispiel einer Texterkennung}{\cite{OCRBSP}}{itm:ocrbsp}{0.7}

Die ersten Versuche einer automatischen Zeichenerkennung lassen sich auf die 30er Jahre datieren. Die damals entworfene Maschine für das künstliche Lesen konnte mit einem Mustervergleich die zehn arabischen Ziffern automatisch erkennen. Solche Texterkennungssysteme konnten sich vor allem sehr früh bei Banken und Versicherungen etablieren. Bereits zu Beginn der 60er Jahre war es möglich, mit entsprechenden Rechnern, geschriebene oder gedruckte Zeichen auf Belegen zu identifizieren.

In den folgenden Jahren gelang dann aber auch der Durchbruch beim Erkennen von Buchstaben. Dabei war die Anzahl der benötigten Schriftarten jedoch sehr begrenzt. Die erste Schriftfamilie, OCR-A, beinhaltete neben Ziffern und Großbuchstaben auch 30 Sonderzeichen. Die Weiterentwicklung davon, OCR-B, ermöglichte auch die Erkennung von Kleinbuchstaben.

In den 70er Jahren haben sich bei Banken und Versicherungen schließlich intelligentere Systeme etabliert, die neben ungenormten Schriftarten auch Handschriften erkennen konnten. Da diese Lesegeräte Komplettsysteme waren, also aus Hardware und Software bestanden, waren die Preise dementsprechend hoch.

Erst seit Mitte der 80er Jahre etablierten sich, aufgrund der Entwicklung von Flachbett- und anderen Scannern, sowie leistungsfähigeren Computern, billigere Systeme, die gute Lösungen anboten. Diese OCR-Lösungen haben sich im Laufe der Jahrzehnte stetig weiterentwickelt, bis zu der professionellen Software, die man heute im Handel oder frei verfügbar im Internet findet.

\subsubsection{OCR-Verfahren}
Das Verfahren zur optischen Zeichenerkennung teilt sich grob gesagt in drei Teile:
\begin{itemize}
\item Seiten- und Gliederungserkennung
\item Mustererkennung
\item Umwandlung in das Ausgabeformat
\end{itemize}
Zudem gibt es verschiedene Arten der konkreten Zeichenerkennung.

\paragraph{Bitmustervergleich}
Ein besonders einfaches und wahrscheinlich das älteste Verfahren zur Zeichenerkennung ist der Bitmustervergleich (Matrizenvergleich). Das in den 30er Jahren entwickelte Verfahren vergleicht Zeichen miteinander, indem es die Differenz des digitalisierten Zeichens zu den gespeicherten Zeichenmustern betrachtet. Wenn ein betrachtetes Zeichen eine geringe Differenz zum gespeicherten Muster zeigt, wird es als dieses Zeichen identifiziert. Für jedes Zeichen existiert also eine Matrix, in der dieses Zeichen in ein Pixelmuster zerlegt wird.

\insertpicture{images/ocr/bitmuster.jpg}{Bitmustervergleich}{\cite{OCRB}}{itm:bitm}{0.7}

Bei diesem Vergleich wird das spezifische Pixelmuster des gescannten Zeichens nacheinander mit den vorhandenen Mustern in einer Datenbank verglichen. Dadurch wird durch die Übereinstimmung der Bildpunkte eine Korrelation errechnet. Die Schwierigkeiten bei diesem Verfahren bestehen darin, dass die beiden zu vergleichenden Bitmuster selten wirklich identisch sind. Das liegt einerseits an der Qualität des gescannten Zeichens, welche von Helligkeit und Kontrast abhängig ist. Andererseits könnten beim Scanvorgang selbst einige Verzerrungen oder Verschmutzungen auftreten. Die Größenunterschiede können zusätzlich eine wesentliche Rolle spielen, da die Muster zunächst auf eine einheitliche Größe angepasst werden müssen. Bei diesem Vorgang können wichtige Detailinformationen verloren gehen.

Um diesen Problemen aus dem Weg zu gehen, versucht man mit Hilfsmitteln, sogenannten Normierungsverfahren, die Konturen der Zeichen zu begradigen. So könnten Zeichen, die auch geringe Abweichungen zu den Musterzeichen aufweisen, erkannt werden. Die erzielte Genauigkeit beim Erkennen der Zeichen ist ein wesentlicher Faktor zur Beurteilung der verschiedenen Verfahren. Beim Bitmustervergleich ist die Erkennungsgenauigkeit einfach zu niedrig. Aufgrund dieser Tatsache hat sich das Verfahren auch nicht durchsetzen können. Ein Bitmustervergleich ist nur dann vorteilhaft, wenn die Vorlagen eine sehr gute Qualität haben und wenige Schriftarten benutzt wurden. Unter diesen Voraussetzungen ist ein Bitmustervergleich meist schneller als die anderen Methoden.

\paragraph{Klassifikation}
Bei der Klassifikation handelt es sich um ein komplexeres, aber auch flexibleres Verfahren. Die Zeichen werden hier anhand sogenannter Klassen analysiert. Es werden nicht alle Pixel der Zeichen, sondern nur spezifische Merkmale untersucht, die wiederum in einzelne Klassen unterteilt werden. Die Entwickler des Verfahrens können bestimmen, nach welchen Klassen unterteilt wird und wie viele Klassen es überhaupt gibt.

\insertpicture{images/ocr/klassi.jpg}{Klassenbaum für Merkmalsanalyse}{\cite{OCRB}}{itm:klassi}{1.0}

In einem Klassenbaum werden die Zeichen systematisch anhand ihrer Merkmale in Klassen unterteilt. Innerhalb der Klassen muss dann wieder eine weitere Klassifikation stattfinden, um am Ende des Prozesses ein eindeutiges Zeichen zuzuordnen. Es kann auch durchaus vorkommen, dass verschiedene Zeichen in mehreren Klassen vorkommen. Typische Kriterien für die Klassenbildung sind zum Beispiel die Anzahl der Zyklen, die Anzahl der Teile und die Eindringtiefe (Größe der Zeichen).

Diese Merkmalsanalyse liefert zu jedem Zeichen einen Merkmalsvektor mit entsprechenden Merkmalseinträgen. Den Merkmalen werden also konkrete Werte, die diese Merkmale beschreiben, zugeordnet. Sobald ein solcher Vektor mit den Merkmalen eines schon bekannten Zeichens übereinstimmt, kann das Zeichen identifiziert werden.

Durch diese Umstände reagiert dieses Verfahren viel flexibler auf verschiedene Schriftarten. Nur bei sehr starken Abweichungen der Merkmale kann es zu Schwierigkeiten bei der Analyse kommen. Die Auswahl der richtigen Klassenmerkmale und der Anzahl der nötigen Klassen ist entscheidend für dieses Verfahren. Bei zu starken Unterschieden im Schriftbild kann es jedoch zur Überforderung dieser Methode kommen.

\paragraph{Topologische Analyse}

Diese Methode wird auch strukturelle Formenanalyse genannt und orientiert sich, ebenso wie die Klassifikation, an spezifischen Eigenschaften der Zeichen und nicht an umfangreichen Mustervergleichen.

Der erste Schritt bei der topologischen Analyse ist die Reduzierung des Pixelbilds auf dessen Grundelemente. Dieser Vorgang wird Vektorisierung genannt. Die überflüssigen Pixel werden also alle entfernt und es entsteht ein ,,Zeichenskelett". Danach folgt die eigentliche Zeichenanalyse. Das Verfahren sucht nun nach Beschreibungen, die mit den Einzelelementen des reduzierten Zeichens übereinstimmen. 

\insertpicture{images/ocr/vektor.jpg}{Vektorisierung eines Zeichens}{\cite{OCRB}}{itm:vektor}{0.5}

Diese Methode ermöglicht eine sehr fehlertolerante Zeichenerkennung. Sie benutzt komplexe Algorithmen, konzentriert sich aber nur auf wenige Elemente und erreicht dadurch eine angemessene Geschwindigkeit.

\paragraph{Neuronale Netze}
Neuronale Netze sollen die Schwächen der bereits genannten Verfahren beheben. Mit solchen neuronalen Netzen wird versucht, intelligentes Verhalten auf Computern nachzuvollziehen. Dabei stellt die Neuroinformatik eine Alternative zur klassischen algorithmischen Informatik dar. Die parallele und verteilte Informationsverarbeitung selbst geschieht mit Hilfe einer Vielzahl von Elementen, den sogenannten Neuronen.

Eine wesentliche Eigenschaft bei diesem Verfahren ist die Selbstprogrammierung. Das System kann sein Wissen durch selbstständiges Lernen erweitern. Das neuronale Netz muss aber zunächst kalibriert werden, dies geschieht beispielsweise mit einem Training aus Identifikationsmustern. Sobald das System ein vorliegendes Problem dann mit einem vernachlässigbaren Fehler lösen kann, kann die Kalibrierung abgeschlossen werden.

\newpage

Die Synapsen eines neuronalen Netzes, also die Verbindungen zwischen den Neuronen, sind nicht statisch und können sich während des Lernprozesses verändern. Es können neue Synapsen entstehen, bestehende Kontakte können ihren Übertragungswiderstand ändern oder ganz aufgelöst werden. Besonders bei der handschriftlichen Erkennung haben neuronale Netze in den letzten Jahren bessere Ergebnisse geliefert als die konkurrierenden Verfahren. Durch eine zusätzliche Erhöhung der Rechenleistung mittels GPU-Implementierungen, konnten Wissenschaftler mit dieser Methode viele Wettbewerbe der Mustererkennung gewinnen. \cite{OCRB}

\subsubsection{ICR und IWR}
Bei der Intelligent Character Recognition werden die digitalen Abbilder der Zeichen mit Wörterbüchern verglichen und anschließend wird die wahrscheinliche Fehlerfreiheit der Zeichen analysiert. Abhängig von dieser wahrscheinlichen Fehlerfreiheit wird das Zeichen identifiziert oder einer erneuten Bewertung unterzogen.

Die Intelligent Word Recognition vergleicht Einzelzeichen, die nicht separat erkannt werden können, mit Wörterbüchern. Die Erkennungsgenauigkeit ist von der Größe des eingebundenen Wörterbuchs abhängig. IWR liefert besonders bei der Handschrifterkennung gute Erfolge.

\subsubsection{Implementierung}
In den folgenden Kapiteln ist die Implementierung des OCR-Moduls beschrieben.
\paragraph{Tesseract OCR und pytesseract-Modul}
Der erste Schritt zur Implementierung war die Evaluierung der geeigneten OCR-Software. Diese wurde im Evaluierungssprint des Projektes evaluiert. Es wurden drei Softwarepakete evaluiert: Tesseract OCR (pytesseract), OCRopus und OmniPage Ultimate. Nach dem Vergleich dieser Lösungen hinsichtlich mehrerer Kriterien fiel die Entscheidung auf die tesseract-Engine und das dazugehörige Python-Modul pytesseract.

Um Tesseract-OCR (engine) zu installieren, installiert man die folgenden Pakete auf dem Server:
\begin{itemize}
\item tesseract-ocr
\item tesseract-ocr-deu
\end{itemize}

\newpage

Zum Testen der Analyse führt man tesseract mit folgendem Befehl in der Commandline aus:
\begin{lstlisting}[caption={tesseract-Ausführung}, language=bash]
tesseract test3.jpg out3
\end{lstlisting}
\cite{TESS1} \cite{TESS2}

Hier erkennt man das analysierte Bild, sowie den Output der tesseract-Engine.

\insertpicture{images/ocr/fresh.jpg}{Beispielbild für OCR-Analyse}{(selfmade)}{itm:fresh}{0.8}

Output:

THE\_FRESH\_STEP

Adamski, Coric, Schwertberger

Entwicklung einer neuen Webseite.

die alle Abteilungen. Werlstatten und A / m

Für die Installation der Python-Anbindung pytesseract sind folgende Befehle notwendig.

\begin{lstlisting}[caption={pytesseract-Installation}, language=bash]
apt-get install python3
apt-get install python3-pip
pip3 install pytesseract
apt-get install python3-pil
\end{lstlisting}
\cite{PYTES} \cite{PYTES2} \cite{PYTES3}

Mit einem Testscript in Python kann die optische Zeichenanalyse ausgeführt werden.

\begin{lstlisting}[caption={pytesseract-Code}, language=Python]
import pytesseract
from PIL import Image
print (pytesseract.image_to_string(Image.open('test3.jpg')))
\end{lstlisting}

\paragraph{Implementierung des OCR-Moduls}
Um Bilder hochladen zu können und eine Bild-zu-Text-Analyse zu ermöglichen, wurde ein OCR-Modul implementiert. Die Idee dahinter ist, dass die Benutzer unserer Hefte möglichst einfach Bilder auswählen und einer Zeichenanalyse (OCR) unterziehen können. Dabei werden prinzipiell die Dateiformate .jpeg .png und .gif akzeptiert.

Bei der optischen Zeichenanalyse (OCR) wird der am Bild vorhandene Text durch eine OCR-Engine analysiert und in ein Textformat umgewandelt. Für unsere Lösung wurde das python-Framework pytesseract mit der OCR-Engine tesseract benutzt.

Um ein Bild zu analysieren, klickt der User zunächst auf folgenden Button im Heft:

\insertpicture{images/ocr/bu.png}{OCR-Button}{(selfmade)}{itm:but}{0.6}

Darauf öffnet sich ein Dialog mit einem Dateieingabefeld:

\insertpicture{images/ocr/di.png}{OCR-Dialog}{(selfmade)}{itm:di}{0.8}

Nachdem auf den Button ,,Analysieren" geklickt wurde, wird das Bild auf den Server geladen und mittels OCR analysiert. Das Ergebnis dabei ist ein neu erstelltes Textelement im Heft mit dem textuellen Inhalt des angegebenen Bildes.

Wie schon erwähnt, erscheint bei Klick auf den OCR-Button ein Dialog, in welchem die zu analysierende Bilddatei angeben werden kann. Bei Klick auf den Button ,,Analysieren" wird folgende Subroutine aufgerufen:

\begin{lstlisting}[caption={Upload OCR-File}, language=Python]
$scope.uploadOCRFile = function(){
        var file = $scope.ocrFile;
        if((file.type == "image/jpeg" || file.type == "image/png" ||
        	file.type == "image/gif") && file.size < 5242880) {
            $scope.errormessage = "";
            var uploadUrl = "/api/analyseOCR";
            var message = fileUpload.uploadFileToUrl(file, uploadUrl);
            message.then(function(data) {
                data_data = "{\"data\":\""+data['ocrt']+"\"}";
                $scope.addelement('textarea', data_data);
                $window.location.reload();
                $window.location.reload();
            });
            ngDialog.close({
                template: 'ocrFileDialog',
                controller: 'notebookEditCtrl',
                className: 'ngdialog-theme-default',
                scope: $scope
            });
        }else{
            if(file.size > 5242880) {
                $scope.errormessage = "file size is more than 5MB";
            }else{
                $scope.errormessage = "filetyp is not supported";
            }
        }
    };
\end{lstlisting}

Hier ist zu sehen, dass zunächst der Dateityp und die Dateigröße überprüft wird. Wenn alles den Kriterien entspricht wird die Methode \textit{uploadFileToUrl()} aufgerufen. Unter der URL \textit{url(r'\^{}api/analyseOCR', 'dsn.views.notebook\_views.view\_analyseOCR', name=,,analyseOCR")} findet sich die Python-Methode \textit{view\_analyseOCR()}.

\newpage

In dieser Methode erhält das File einen neuen, zufällig generierten Namen und wird auf den Server lokal hochgeladen. Dann wird schließlich die Methode, die für das eigentliche Analysieren zuständig ist, aufgerufen:

\begin{lstlisting}[caption={OCR-Analyse}, language=Python]
ocrtext=analyseOCR(os.getcwd()+"/dsn/static/upload/"+filename+"."+typ)
\end{lstlisting}

Schließlich kommt in der Methode analyseOCR das pytesseract-Framework zum Einsatz:

\begin{lstlisting}[caption={analyseOCR mittels pytesseract}, language=Python]
def analyseOCR(file):
	s = str(pytesseract.image_to_string(
		Image.open(file)).encode(sys.stdout.encoding,
		errors='replace'))
    s = s[2:-1]
    s = s.replace("\\n", "<br />").replace("\\x", "")
    return s
\end{lstlisting}

Nach der Analyse wird der erkannte Text als JSONResponse zurückgegeben und das lokal hochgeladene Bild wird wieder vom Server gelöscht.

\begin{lstlisting}[caption={Fileentfernung und Rückgabe des OCR-Textes}, language=Python]
os.remove(os.getcwd()+"/dsn/static/upload/"+filename+"."+typ)
return JsonResponse({'ocrt': ocrtext})
\end{lstlisting}

Abschließend wird mit dem daraus analysierten Text ein neues Textelement im Heft erzeugt. Dazu wird die \textit{addelement()} Methode aufgerufen. Aus folgendem Bild ergibt sich dann das folgende Textelement.

\insertpicture{images/ocr/bspbild.jpg}{Beispielbild für OCR-Analyse}{(selfmade)}{itm:bsp}{0.55}

\insertpicture{images/ocr/bsptext.png}{Erzeugtes Textelement}{(selfmade)}{itm:text}{0.35}

\subsubsection{Ausblick}
Eine Optimierung des OCR-Moduls hinsichtlich Erkennungsgenauigkeit und Handschrifterkennung wurde angedacht. In Zukunft könnte man das OCR-Modul durch entsprechendes (automatisiertes) Training in dieser Hinsicht weiterentwickeln. Eine höhere Fehlertoleranz bei Bildern mit schlechter Qualität ist ebenso wünschenswert.

